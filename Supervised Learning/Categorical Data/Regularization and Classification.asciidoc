== 1.Preprocessing- CATEGORICAL DATA

== 1.1 Import libraries


+*In[83]:*+
[source, ipython3]
----
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
----

== 1.2 Import Data


+*In[84]:*+
[source, ipython3]
----
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"

# Assign column names to the dataset
names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']


df=pd.read_csv(url,names=names)
df.head(4)
----


+*Out[84]:*+
----
[cols=",,,,,",options="header",]
|===
| |sepal-length |sepal-width |petal-length |petal-width |Class
|0 |5.1 |3.5 |1.4 |0.2 |Iris-setosa
|1 |4.9 |3.0 |1.4 |0.2 |Iris-setosa
|2 |4.7 |3.2 |1.3 |0.2 |Iris-setosa
|3 |4.6 |3.1 |1.5 |0.2 |Iris-setosa
|===
----

== 1.2 To know how many different classes we in columns `Class' are.


+*In[85]:*+
[source, ipython3]
----
df['Class'].unique()
----


+*Out[85]:*+
----array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)----

== 1.3 General Info about DataSet


+*In[86]:*+
[source, ipython3]
----
df.info()
----


+*Out[86]:*+
----
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 150 entries, 0 to 149
Data columns (total 5 columns):
 #   Column        Non-Null Count  Dtype  
---  ------        --------------  -----  
 0   sepal-length  150 non-null    float64
 1   sepal-width   150 non-null    float64
 2   petal-length  150 non-null    float64
 3   petal-width   150 non-null    float64
 4   Class         150 non-null    object 
dtypes: float64(4), object(1)
memory usage: 6.0+ KB
----

== 1.4 Investigate of NaN Values in columns


+*In[87]:*+
[source, ipython3]
----
df.isnull().sum()
----


+*Out[87]:*+
----sepal-length    0
sepal-width     0
petal-length    0
petal-width     0
Class           0
dtype: int64----

== 1.5 Plotting for general overview of the DataSet


+*In[88]:*+
[source, ipython3]
----
ax=sns.heatmap(df.corr(),square=True,cmap='YlOrRd')
----


+*Out[88]:*+
----
![png](output_12_0.png)
----


+*In[89]:*+
[source, ipython3]
----
g = sns.pairplot(df, plot_kws={'color':'green'})
----


+*Out[89]:*+
----
![png](output_13_0.png)
----

== 2. Processing

== 2.1 Define of X,y


+*In[90]:*+
[source, ipython3]
----
X=df.iloc[:,:-1]
y=df.iloc[:,-1:]
----

== 2.2 Define of train-test-split


+*In[91]:*+
[source, ipython3]
----
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)
----

== 2.3 FeatureScaling

== 2.3.1 Call StandrdScaler


+*In[92]:*+
[source, ipython3]
----
from sklearn.preprocessing import StandardScaler

scaler=StandardScaler()
scaler.fit(X_train)
X_train=scaler.transform(X_train)
X_test=scaler.transform(X_test)
----

== 2.4 Kneighbors Classifier


+*In[96]:*+
[source, ipython3]
----
from sklearn.neighbors import KNeighborsClassifier
classifire=KNeighborsClassifier(n_neighbors=5)
classifire.fit(X_train,y_train)
----


+*Out[96]:*+
----
<ipython-input-96-9fe8cd48d698>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  classifire.fit(X_train,y_train)
KNeighborsClassifier()----

== 2.5 Prediction


+*In[98]:*+
[source, ipython3]
----
y_pred=classifire.predict(X_test)
----

== 2.6 Confusion Matrix


+*In[103]:*+
[source, ipython3]
----
from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
----


+*Out[103]:*+
----
[[10  0  0]
 [ 0  9  0]
 [ 0  0 11]]
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        10
Iris-versicolor       1.00      1.00      1.00         9
 Iris-virginica       1.00      1.00      1.00        11

       accuracy                           1.00        30
      macro avg       1.00      1.00      1.00        30
   weighted avg       1.00      1.00      1.00        30

----
